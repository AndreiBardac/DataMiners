{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 ~ Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import numpy as np\n",
    "\n",
    "#read data\n",
    "\n",
    "datat = 'C:/Users/20200876/Downloads/HW1/HW1/heart_train_data.csv'\n",
    "datav = 'C:/Users/20200876/Downloads/HW1/HW1/heart_validate_data.csv'\n",
    "\n",
    "train = pd.read_csv(datat)\n",
    "validate = pd.read_csv(datav)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   cp      210 non-null    int64\n",
      " 1   exang   210 non-null    int64\n",
      " 2   thal    210 non-null    int64\n",
      " 3   target  210 non-null    int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 6.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp</th>\n",
       "      <th>exang</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cp  exang  thal  target\n",
       "0   0      1     2       0\n",
       "1   3      0     2       1\n",
       "2   3      0     2       1\n",
       "3   2      0     2       1\n",
       "4   0      0     3       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train.shape\n",
    "#rename columns\n",
    "\n",
    "column_names= ['cp', 'exang', 'thal', 'target']\n",
    "train.columns = column_names\n",
    "\n",
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp        199\n",
       "exang      68\n",
       "thal      486\n",
       "target    117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary of variables\n",
    "\n",
    "train['target'].value_counts()\n",
    "train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    101\n",
      "2     58\n",
      "1     35\n",
      "3     16\n",
      "Name: cp, dtype: int64\n",
      "0    142\n",
      "1     68\n",
      "Name: exang, dtype: int64\n",
      "2    124\n",
      "3     76\n",
      "1     10\n",
      "Name: thal, dtype: int64\n",
      "1    117\n",
      "0     93\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Frequency distribution for values in variables\n",
    "\n",
    "for i in column_names:\n",
    "    \n",
    "    print(train[i].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((147, 3), (63, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define fecture vectors and target variables\n",
    "\n",
    "xb = train.drop(['target'], axis=1)\n",
    "yb = train['target']\n",
    "\n",
    "#split data into trianing and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xb_train, xb_test, yb_train, yb_test = train_test_split(xb, yb, test_size = 0.3, random_state = 0)\n",
    "\n",
    "xb_train.shape, xb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nB = GaussianNB()\n",
    "\n",
    "#Model Fitting\n",
    "\n",
    "nB.fit(xb_train, yb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result Prediction\n",
    "\n",
    "yb_pred = nB.predict(xb_test)\n",
    "yb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.8254\n"
     ]
    }
   ],
   "source": [
    "#Accuracy measurement of the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(yb_test, yb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with criterion entropy index: 0.7500\n"
     ]
    }
   ],
   "source": [
    "#Validate dataset\n",
    "\n",
    "xb_v = validate.drop(['target'], axis=1)\n",
    "yb_v = validate['target']\n",
    "\n",
    "xb_v_train, xb_v_test, yb_v_train, yb_v_test = train_test_split(xb_v, yb_v, test_size = 0.3, random_state = 45)\n",
    "\n",
    "xb_v_train.shape, xb_v_test.shape\n",
    "yb_v_pred = nB.predict(xb_v_test)\n",
    "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(yb_v_test, yb_v_pred)))\n",
    "#print(classification_report(yv_test, yv_pred, target_names=yv_test['target' == 1]))\n",
    "#Therefore, A is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class probabilities\n",
    "\n",
    "#print the first 10 predicted probabilities classes: 0 and 1\n",
    "\n",
    "yb_pred_prob = nB.predict_proba(xb_test)[0:10]\n",
    "yb_pred_prob_df = pd.DataFrame(data=yb_pred_prob, columns=['P(no hearth pb)', 'P(hearth pb)'])\n",
    "\n",
    "yb_pred_prob_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "y_pred1 = nB.predict_proba(xb_test)[:, 1]\n",
    "# adjust the font size \n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "\n",
    "# plot histogram with 10 bins\n",
    "plt.hist(y_pred1, bins = 10)\n",
    "\n",
    "\n",
    "# set the title of predicted probabilities\n",
    "plt.title('Histogram of Predicted probabilities of hearth deasease')\n",
    "\n",
    "\n",
    "# set the x-axis limit\n",
    "plt.xlim(0,1)\n",
    "\n",
    "\n",
    "# set the title\n",
    "plt.xlabel('Predicted probabilities of hearth deasease')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 ~ Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#read data\n",
    "\n",
    "datat = 'C:/Users/20200876/Downloads/HW1/HW1/heart_train_data.csv'\n",
    "datav = 'C:/Users/20200876/Downloads/HW1/HW1/heart_validate_data.csv'\n",
    "\n",
    "dft = pd.read_csv(datat)\n",
    "dfv = pd.read_csv(datav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.head()\n",
    "dft.shape\n",
    "#rename columns\n",
    "\n",
    "column_names= ['cp', 'exang', 'thal', 'target']\n",
    "dft.columns = column_names\n",
    "\n",
    "#dft = dft.iloc[0: , :]\n",
    "dft.info()\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of variables\n",
    "\n",
    "dft['target'].value_counts()\n",
    "dft.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency distribution for values in variables\n",
    "\n",
    "for i in column_names:\n",
    "    \n",
    "    print(dft[i].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define fecture vectors and target variables\n",
    "\n",
    "x = dft.drop(['target'], axis=1)\n",
    "y = dft['target']\n",
    "\n",
    "#split data into trianing and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree with criterion Entropy and depth at most 3\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cdt_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3, random_state=0)\n",
    "\n",
    "#model fitting\n",
    "cdt_entropy.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cdt_entropy.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set accuracy\n",
    "\n",
    "\n",
    "xv = dfv.drop(['target'], axis=1)\n",
    "yv = dfv['target']\n",
    "\n",
    "xv_train, xv_test, yv_train, yv_test = train_test_split(xv, yv, test_size = 0.3, random_state = 45)\n",
    "\n",
    "xv_train.shape, xv_test.shape\n",
    "yv_pred = cdt_entropy.predict(xv_test)\n",
    "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(yv_test, yv_pred)))\n",
    "#print(classification_report(yv_test, yv_pred, target_names=yv_test['target' == 1]))\n",
    "#Therefore, A is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vislauize the tree\n",
    "\n",
    "#import graphviz \n",
    "#plot = tree.export_graphviz(cdt_entropy, out_file=None, \n",
    "                            #  feature_names=x_train.columns,  \n",
    "                            #  class_names=y_train,  \n",
    "                            #  filled=True, rounded=True,  \n",
    "                            #  special_characters=True)\n",
    "\n",
    "#graph = graphviz.Source(plot) \n",
    "\n",
    "#graph \n",
    "\n",
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

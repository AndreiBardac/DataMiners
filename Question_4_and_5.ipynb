{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 ~ Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import numpy as np\n",
    "\n",
    "#read data\n",
    "\n",
    "datat = 'C:/Users/20200876/Downloads/HW1/HW1/heart_train_data.csv'\n",
    "datav = 'C:/Users/20200876/Downloads/HW1/HW1/heart_validate_data.csv'\n",
    "\n",
    "train = pd.read_csv(datat)\n",
    "validate = pd.read_csv(datav)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "train.shape\n",
    "#rename columns\n",
    "\n",
    "column_names= ['cp', 'exang', 'thal', 'target']\n",
    "train.columns = column_names\n",
    "\n",
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of variables\n",
    "\n",
    "train['target'].value_counts()\n",
    "train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency distribution for values in variables\n",
    "\n",
    "for i in column_names:\n",
    "    \n",
    "    print(train[i].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define fecture vectors and target variables\n",
    "\n",
    "xb = train.drop(['target'], axis=1)\n",
    "yb = train['target']\n",
    "\n",
    "#split data into trianing and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xb_train, xb_test, yb_train, yb_test = train_test_split(xb, yb, test_size = 0.3, random_state = 0)\n",
    "\n",
    "xb_train.shape, xb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nB = GaussianNB()\n",
    "\n",
    "#Model Fitting\n",
    "\n",
    "nB.fit(xb_train, yb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result Prediction\n",
    "\n",
    "yb_pred = nB.predict(xb_test)\n",
    "yb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy measurement of the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(yb_test, yb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate dataset\n",
    "\n",
    "xb_v = validate.drop(['target'], axis=1)\n",
    "yb_v = validate['target']\n",
    "\n",
    "xb_v_train, xb_v_test, yb_v_train, yb_v_test = train_test_split(xb_v, yb_v, test_size = 0.3, random_state = 45)\n",
    "\n",
    "xb_v_train.shape, xb_v_test.shape\n",
    "yb_v_pred = cdt_entropy.predict(xb_v_test)\n",
    "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(yb_v_test, yb_v_pred)))\n",
    "#print(classification_report(yv_test, yv_pred, target_names=yv_test['target' == 1]))\n",
    "#Therefore, A is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class probabilities\n",
    "\n",
    "#print the first 10 predicted probabilities classes: 0 and 1\n",
    "\n",
    "yb_pred_prob = nB.predict_proba(xb_test)[0:10]\n",
    "yb_pred_prob_df = pd.DataFrame(data=yb_pred_prob, columns=['P(no hearth pb)', 'P(hearth pb)'])\n",
    "\n",
    "yb_pred_prob_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "y_pred1 = nB.predict_proba(xb_test)[:, 1]\n",
    "# adjust the font size \n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "\n",
    "# plot histogram with 10 bins\n",
    "plt.hist(y_pred1, bins = 10)\n",
    "\n",
    "\n",
    "# set the title of predicted probabilities\n",
    "plt.title('Histogram of Predicted probabilities of hearth deasease')\n",
    "\n",
    "\n",
    "# set the x-axis limit\n",
    "plt.xlim(0,1)\n",
    "\n",
    "\n",
    "# set the title\n",
    "plt.xlabel('Predicted probabilities of hearth deasease')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 ~ Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#read data\n",
    "\n",
    "datat = 'C:/Users/20200876/Downloads/HW1/HW1/heart_train_data.csv'\n",
    "datav = 'C:/Users/20200876/Downloads/HW1/HW1/heart_validate_data.csv'\n",
    "\n",
    "dft = pd.read_csv(datat)\n",
    "dfv = pd.read_csv(datav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.head()\n",
    "dft.shape\n",
    "#rename columns\n",
    "\n",
    "column_names= ['cp', 'exang', 'thal', 'target']\n",
    "dft.columns = column_names\n",
    "\n",
    "#dft = dft.iloc[0: , :]\n",
    "dft.info()\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of variables\n",
    "\n",
    "dft['target'].value_counts()\n",
    "dft.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency distribution for values in variables\n",
    "\n",
    "for i in column_names:\n",
    "    \n",
    "    print(dft[i].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define fecture vectors and target variables\n",
    "\n",
    "x = dft.drop(['target'], axis=1)\n",
    "y = dft['target']\n",
    "\n",
    "#split data into trianing and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree with criterion Entropy and depth at most 3\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cdt_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3, random_state=0)\n",
    "\n",
    "#model fitting\n",
    "cdt_entropy.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cdt_entropy.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set accuracy\n",
    "\n",
    "\n",
    "xv = dfv.drop(['target'], axis=1)\n",
    "yv = dfv['target']\n",
    "\n",
    "xv_train, xv_test, yv_train, yv_test = train_test_split(xv, yv, test_size = 0.3, random_state = 45)\n",
    "\n",
    "xv_train.shape, xv_test.shape\n",
    "yv_pred = cdt_entropy.predict(xv_test)\n",
    "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(yv_test, yv_pred)))\n",
    "#print(classification_report(yv_test, yv_pred, target_names=yv_test['target' == 1]))\n",
    "#Therefore, A is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vislauize the tree\n",
    "\n",
    "#import graphviz \n",
    "#plot = tree.export_graphviz(cdt_entropy, out_file=None, \n",
    "                            #  feature_names=x_train.columns,  \n",
    "                            #  class_names=y_train,  \n",
    "                            #  filled=True, rounded=True,  \n",
    "                            #  special_characters=True)\n",
    "\n",
    "#graph = graphviz.Source(plot) \n",
    "\n",
    "#graph \n",
    "\n",
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
